{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"kkYCqgLkJOLp"},"outputs":[],"source":["!pip install pypdf\n","!pip install -q google-generativeai\n","!pip install langchain"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"s9A8rM-WJOLr"},"outputs":[],"source":["from langchain.text_splitter import RecursiveCharacterTextSplitter\n","import os\n","import PyPDF2\n","import pandas as pd\n","import google.generativeai as palm\n","import textwrap\n","import numpy as np\n","import pandas as pd"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Yly-OR1aJOLs"},"outputs":[],"source":["palm.configure(api_key='AIzaSyAEPONnzffIYBh1cwv9C_MhggcVNphcXBQ')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"SIiNfQG_JOLs","outputId":"a33a542d-8165-48e2-fedd-e985927a4d34"},"outputs":[{"name":"stdout","output_type":"stream","text":["models/embedding-gecko-001\n"]}],"source":["models = [m for m in palm.list_models() if 'embedText' in m.supported_generation_methods]\n","\n","model = models[0]\n","print(model.name)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"LCGqOyx9JOLs"},"outputs":[],"source":["def extract_text_from_pdf(pdf_file_path):\n","  \"\"\"Extracts text from a PDF file and returns it as a string.\n","\n","  Args:\n","    pdf_file_path: The path to the PDF file.\n","\n","  Returns:\n","    A string containing the extracted text from the PDF file.\n","  \"\"\"\n","\n","  # Open the PDF file\n","  pdf_file = PyPDF2.PdfReader(pdf_file_path)\n","\n","  # Get the total number of pages in the PDF file\n","  num_pages = len(pdf_file.pages)\n","\n","  # Iterate over the pages and extract the text\n","  text = \"\"\n","  for page_num in range(num_pages):\n","    page = pdf_file.pages[page_num]\n","    text += page.extract_text()\n","\n","  return text\n","\n","def extract_text_from_all_pdfs_in_folder(folder_path):\n","  \"\"\"Extracts text from all the PDF files in a folder and returns it as a list of strings.\n","\n","  Args:\n","    folder_path: The path to the folder containing the PDF files.\n","\n","  Returns:\n","    A list of strings containing the extracted text from all the PDF files in the folder.\n","  \"\"\"\n","\n","  # Get a list of all the PDF files in the folder\n","  pdf_files = os.listdir(folder_path)\n","\n","  # Extract the text from each PDF file\n","  pdf_texts = []\n","  for pdf_file in pdf_files:\n","    pdf_file_path = os.path.join(folder_path, pdf_file)\n","    pdf_text = extract_text_from_pdf(pdf_file_path)\n","    pdf_texts.append(pdf_text)\n","\n","  return pdf_texts\n","\n","def embed_text(text):\n","  \"\"\"Embeds a text using PaLM.\n","\n","  Args:\n","    text: The text to embed.\n","\n","  Returns:\n","    A numpy array containing the embedding of the text.\n","  \"\"\"\n","\n","  return palm.generate_embeddings(model=model, text=text)['embedding']\n","\n","def create_dataframe_from_pdf_text(pdf_text):\n","  \"\"\"Creates a DataFrame from a PDF text.\n","\n","  Args:\n","    pdf_text: The PDF text.\n","\n","  Returns:\n","    A Pandas DataFrame containing the PDF text and its embedding.\n","  \"\"\"\n","\n","  # Split the PDF text into chunks\n","  text_splitter = RecursiveCharacterTextSplitter(chunk_size=2000, chunk_overlap=200)\n","  text_chunks = text_splitter.split_text(pdf_text)\n","\n","  # Create a DataFrame from the text chunks\n","  # Create an empty DataFrame with column names\n","  df = pd.DataFrame(columns=['Text'])\n","\n","# Append data to the DataFrame later\n","  df['Text'] = text_chunks\n","\n","  # df = pd.DataFrame(text_chunks)\n","  # df.columns = ['Text']\n","\n","  # Get the embeddings of each text chunk and add them to the DataFrame\n","  df['Embeddings'] = df['Text'].apply(embed_text)\n","\n","  return df\n","\n","if __name__ == \"__main__\":\n","  folder_path = \"new docs\"\n","\n","  # Extract the text from all the PDF files in the folder\n","  pdf_texts = extract_text_from_all_pdfs_in_folder(folder_path)\n","\n","  # Create a DataFrame from each PDF text\n","  df_list = []\n","  for pdf_text in pdf_texts:\n","    df = create_dataframe_from_pdf_text(pdf_text)\n","    df_list.append(df)\n","\n","  # Concatenate the DataFrames\n","  df = pd.concat(df_list)\n","\n","  # Print the DataFrame\n","  print(df)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3Ej_YvRfJOLt"},"outputs":[],"source":["df.to_csv('data1.csv')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"LrdASoVyJOLt","outputId":"c4e9d1a9-2cd3-4f6d-d3e4-e79069d5db10"},"outputs":[{"name":"stdout","output_type":"stream","text":["models/text-bison-001\n"]}],"source":["text_models = [m for m in palm.list_models() if 'generateText' in m.supported_generation_methods]\n","\n","text_model = text_models[0]\n","print(text_model.name)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wwu98IaOJOLu"},"outputs":[],"source":["query = '''Generate 5 Multiple Choice Questins from Chemistry subject according to the syllabus.'''\n","k=3\n","def find_best_passage(query, dataframe):\n","    \"\"\"\n","    Compute the distances between the query and each document in the dataframe\n","    using the dot product and return the top three passages concatenated.\n","    \"\"\"\n","    query_embedding = palm.generate_embeddings(model=model, text=query)\n","    dot_products = np.dot(np.stack(dataframe['Embeddings']), query_embedding['embedding'])\n","    # Get the indices of the top three passages with highest dot products\n","    top_indices = np.argsort(dot_products)[-3:][::-1]  # Get the top 3 indices in descending order\n","    top_passages = [dataframe.iloc[i]['Text'] for i in top_indices]  # Get the top 3 passages\n","    concatenated_text = \" \".join([f\"Passage {i+1}: {text}\" for i, text in enumerate(top_passages)])\n","    return concatenated_text\n","\n","passage = find_best_passage(query, df)\n","\n","def make_prompt(query, relevant_passage):\n","  escaped = relevant_passage.replace(\"'\", \"\").replace('\"', \"\").replace(\"\\n\", \" \")\n","  prompt = textwrap.dedent(\"\"\"You are a question-generating bot tasked with creating insightful questions related to subject is mentioned in query \\\n","    Your questions should be thoughtful and aim to explore various aspects of the given topic. \\\n","    If the passage is irrelevant to the question, you may ignore it. \\\n","    If you do not know how to formulate a question, you may state that explicitly.\n","\n","    QUERY: '{query}'\n","    PASSAGE: '{relevant_passage}'\n","\n","    QUESTIONS:\n","  \"\"\").format(query=query, relevant_passage=escaped)\n","\n","  return prompt\n","\n","prompt = make_prompt(query, passage)\n","\n","temperature = 0.5\n","answer = palm.generate_text(prompt=prompt,\n","                            model=text_model,\n","                            candidate_count=1,\n","                            temperature=temperature,\n","                            max_output_tokens=1000)\n","for i, candidate in enumerate(answer.candidates):\n","  print(f\"{candidate['output']}\\n\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KJyZ0FzvJOLu"},"outputs":[],"source":["print(passage)"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.2"},"orig_nbformat":4,"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":0}